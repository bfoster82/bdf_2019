from elasticsearch import Elasticsearch, helpers
import pprint
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import functools
import time
import pickle
import pandas as pd
es=Elasticsearch('http://enron:spsdata@129.105.88.91:9200')
query={"query" : {"match_all" : {}}}
count_results=es.search(size=0,index='enron',doc_type='email',body=query)
msgs=es.search(index='enron',doc_type='email',body=query)
for key in msgs.keys(): print (key)
def timeit(fn):
    @functools.wraps(fn)
    def inner(*args,**kwargs):
        start_time = time.time()
        retval = fn(*args,**kwargs)
        duration = time.time()- start_time
        print('{} took {:4.2f} sec.'.format(fn,duration))
        return retval
    return inner
@timeit
def scrollMsgs(nMsgs=250762):
    msgList=list()
    msgCnt=0
    if nMsgs > 250762:
        print('You\'re trying to get too many messages!')
        return
    query={"query" : {"match_all" : {}}}
    scanResp=helpers.scan(client= es, query=query, scroll= "10m", index="",
                       doc_type="email", timeout="10m")
    for msg in scanResp:
        if msgCnt % 500 == 0:
            print('.',end='')
        msgList.append(msg)
        msgCnt +=1
        if msgCnt == nMsgs:
            print("\nDone!")
            break
    return(msgList)
msgs=scrollMsgs()
with open('msgs.pkl','wb') as f:
    pickle.dump(msgs,f)
#all recs toselectdocs
selectdocs = [resp['_source'] for resp in msgs]
print(len(selectdocs))

#create an empty list

dictList=[]
# get Headers,body message-ID, Date, From, To 
#loop through to get the data in to a dictionary
#and append it to the list
for msg in selectdocs:
    try:
        headers=msg['headers']
        msgBody = msg['body']
        msgID=headers['Message-ID']
        msgDate=headers['Date']
        msgFrom=headers['From']
#cleanup and split   
        msgTo=headers['To']
        msgTo = msgTo.replace("\n", "")
        msgTo = msgTo.replace("\t", "")
        msgTo = msgTo.replace(" ", "")
       
        msgTo = msgTo.split(",")
# loop 'To' email addresses msgID,From,To,Body,Date to dictList.        
    except:
        msgTo=''     
    for mTo in msgTo:
        dictList.append({'msgID':msgID,'To':mTo.strip(),'From':msgFrom.strip(),
                         'Date':msgDate,'Body':msgBody})
#add to a dataframe
df_msgs = pd.DataFrame(dictList)
#format the date
df_msgs['Date'] = pd.to_datetime(df_msgs['Date'])
df_msgs["Date"] = df_msgs["Date"].dt.strftime("%m-%d-%Y")
#import re
import re
#prepare a regex for Ken Lay from
patternFrom = re.compile("ken.lay|kenneth.lay|chairman.ken|\
ken.board|klay|ken.skilling");
#prepare a regex for Lay To
patternTo = re.compile("ken.lay|kenneth.lay|chairman.ken|ken.board|klay@enron|\
kennethlay|ken.skilling|ken.communications|91.kenneth|e-mail<.'kenneth.|\
e-mail<.kenneth|ken_lay");
#add a counter column to grouby From addresses
df_msgs['COUNTER'] = 1  
#select all the Ken Lay From
msg_from_kenLay = df_msgs[df_msgs['From'].str.contains(
    patternFrom)].groupby(['From'])['COUNTER'].sum()  
#select all the Ken Lay To.
msg_to_kenLay = df_msgs[df_msgs['To'].str.contains(
    patternTo)].groupby(['To'])['COUNTER'].sum()

#p,1
df_kenLay = msg_from_kenLay.append(msg_to_kenLay)
print("Emails from and to Ken Lay", df_kenLay.sum())
#p.2
df = pd.DataFrame(df_kenLay)
df.reset_index(level=0, inplace=True)
#group 
all_kenLay  = df.groupby(["index"])["COUNTER"].sum()
#sort 
all_kenLay.sort_values(ascending = False)
# P.3
print("Email address from Ken Lay ",msg_from_kenLay.sum())
print("Email address to Ken Lay ",msg_to_kenLay.sum())
print(msg_from_kenLay)
print ('-' * 40)
print(msg_to_kenLay)

#p.4
df_temp = df_msgs
df_temp["Count"] = 1
#all the email addresses who sent to Ken Lay
df_temp = df_temp[(df_msgs['To'].str.contains(patternTo))]
#group and count
number_to_klay = df_temp.groupby(["From"])["Count"].sum()
#sort based on count
number_to_klay = number_to_klay.sort_values(ascending = False)
#display the email address with maximum count
print("Person Who sent the most emails to Ken Lay:", number_to_klay.index[0])
#display the count
print("Number of emails sent by", number_to_klay.index[0],\
      "to Ken Lay:", number_to_klay[0])
#create a temp DF
df_temp = df_msgs
df_temp["Count"] = 1
#get all the email addresses who from Ken Lay
df_temp = df_temp[(df_msgs['From'].str.contains(patternTo))]
#group by the to column and count
number_from_klay = df_temp.groupby(["To"])["Count"].sum()
#sort the list 
number_from_klay = number_from_klay.sort_values(ascending = False)
#display the email addrees
print("Person who received the most emails from Ken Lay:",\
      number_from_klay.index[0])
#display the count 
print("Number of emails received by", number_from_klay.index[0],\
      "From Ken Lay:", number_from_klay[0])
# part 5 extract the From and TO dataframes 
df_from = df_msgs[df_msgs['From'].str.contains(patternFrom)] 
df_to = df_msgs[df_msgs['To'].str.contains(patternTo)]
#Bancruptcy Dec.2 2001
#filter emails for before
before_bank = df_from['Date'] < '12-02-2001'
#display the no of emails
print("Emails sent before bankruptcy:",\
      before_bank.sum())
#filter emails after Bankruptcy
after_bank = df_from['Date'] >= '12-03-2001'
#display 
print("Emails sent after bankruptcy:",\
      after_bank.sum())
#filter emails 
before_bank_to = df_to['Date'] < '12-02-2001'
#display 
print("Emails received before bankruptcy:",\
      before_bank_to.sum())
#filter emails 
after_bank_to = df_to['Date'] >= '12-03-2001'
#display 
print("Emails received after bankruptcy:",\
      after_bank_to.sum())
print("Emails sent by and to Ken Lay decreased after bankruptcy")
#p.6
#regex for Athur Andersen
regex = re.compile("arthur andersen|andersen|anderson|arthur anderson|\
accounting firm|accounting",flags=re.IGNORECASE)
#apply a lambda which return true or false based on the regex
arthur_count = df_from[["Body"]].applymap(
    lambda x: bool(re.search(regex, x))).any(axis=1)
#count the no
print("Emails sent from Ken Lay which mention \
Arthur Andersen:",arthur_count.sum())
#apply a lambda which return true or false based on the regex-
arthur_count = df_to[["Body"]].applymap(lambda x: \
                                        bool(re.search(regex, x))).any(axis=1)
#count the no of true values in the arthur_count list by sum().
print("Number of emails received by Ken Lay which mention \
Arthur Andersen:",arthur_count.sum())
#pt.7
uni=set([])
for msg in msgs:
    uni.add(msg['_id'])
unilist=(list(uni))
len(unilist)
print(len(unilist)==len(msgs))
# The number of _id is less than the number of emails.  I am not sure why this
#the case
